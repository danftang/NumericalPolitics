\documentclass[a4paper]{article}
%\documentclass[a4paper]{report}
\usepackage{graphics}
\usepackage{breqn}
\setlength{\parindent}{0mm}
\setlength{\parskip}{1.8mm}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{proof}{Proof}
\title{On model reduction and equivalence in ABMs}
%%\date{$28^{th}$ August, 2007}
\author{Daniel Tang}
%%\linespread{1.3}

\begin{document}
\maketitle
\section{Poisson models and Markov processes}

Let a Poisson model be a dynamic system on some discrete state space such that the probability that the process will transition from state $x$ to state $x'$ in time $dt$ is given by $\rho('x|x)dt$. If we let $\rho_{ij}$ be a transition matrix such that
\[
\rho_{ij} = 
\begin{cases}
\rho(i|j) & \text{if } i \ne j\\
\sum_{k \ne j} -\rho(k|j) & \text{if } i = j
\end{cases}
\]
and let $X$ be a vector representing a probability distribution over the state space, then we can define the Poisson model as a continuous time dynamic system
\[
\frac{dX}{dt} = \rho X
\]
so that
\[
X(t) = e^{\rho t}X(0) = e^{(\mu - I)rt}X(0) = \sum_{k=0}^\infty \frac{ (rt)^k e^{-rt}}{k!}\mu^kX(0)
\]
where $r = \max_j \sum_{k \ne j} \rho(k|j)$ is a scalar and $\mu = \frac{\rho}{r} + I$. It can be seen that each entry of $\mu$ is non-negative and the sum of entries in each column is 1, so $\mu^k X(0)$ is the state of a discrete time Markov process at time $k$.

Since $\mu rt$ commutes with $Irt$ we can separate and expand to give
\[
X(t) = e^{-rt}e^{\mu rt}X(0) = \sum_{k=0}^\infty \frac{ (rt)^k e^{-rt}}{k!}\mu^kX(0)
\]
which we recognize as a sum of powers of $\mu$ weighted with a Poisson distribution. So, each continuous-time Poisson model $\rho$ has an associated discrete-time Markov process $\mu = \frac{\rho}{r} + I$. The two are related by the fact that, for a given start state distribution, the state of the Poisson model at time $t$ is the weighted sum of states in a trajectory of the Markov process, where the weights are given by a Poisson distribution with rate $rt$.

This means, among other things, that as $t \to \infty$ the state distribution of a Poisson model tends to a uniform distribution over the attractor of its associated Markov model. So every Poisson model tends to a steady state distribution (i.e. a single point in distribution space).

\section{Social norms and social agents}

Let a \textit{social role} be a tuple $\left<S, \sigma_0, A, Q\right>$ where $S$ is a domain of social states of the actor of which $\sigma_0$ is the default state given at the beginning of an episode, $A$ is a domain of social actions that can be performed by the actor and $Q$ is a social-quality function in $S \times A \to \mathcal{R}$. 

Let a \textit{social norm} be defined as a tuple $\left<r_1, r_2, \tau \right>$ where $r_1$ and $r_2$ are social roles and $\tau$ is a state transition function in $S_1 \times A \times S_2 \to S_1 \times S_2$ saying that if two agents playing roles $r_1$ and $r_2$ are in states $s_1$ and $s_2$ respectively and agent 1 performs action $a$ on agent 2 then, after the action the agents have state $s'_1$ and $s'_2$ respectively. [can this be separated by defining the social quality of actions \textit{performed on other} given other's state? In this way, my behaviour towards you is constrained by your role, not mine. Can we define social state change solely by own actions? ]

Let a \textit{social connection} be a tuple $\left<N, s_1, s_2 \right>$ where $N$ is a social norm, $s_1$ is the social state of the first agent in $N$ and $s_2$ is the social state of the second.

Let a \textit{social network} be a directed graph, where each edge is associated with a social connection. So, each agent in a social network can be thought of as being in a number of social states (one for each edge) and each social state comes with a constraint on behaviour in the form of the social Q-functions.

Let a \textit{social agent} be a node in a social network. The agent's internal state is the set of social states on its edges. The agent's behaviour towards each agent it has a social connection with is constrained by the Q-function associted with that connection.

Agents in a social network need not, and often do not, physically exist. God, the government and Microsoft do not exist but many people model them as agents to which they have social connections. There raises no difficulty as long as the physical meaning of social actions involving the non-existant agent don't require its physical presence, and there's no reason it should need to. These actions can be instrumental in the coordination of behaviour between physically existant agents. I can be employed by, or sue Microsoft without ever expecting to meet face to face.

\subsection{Social network as closure}

If an agent models its world and assumes every other agent models the world in the same way, then evey agent in the model contains an instance of the model and we have an infinite regression, so we need some kind of closure.

If we assume that the state of the social network is public knowlede, through observation, gossip etc. (where X is public knowledge if everyone knows X and it's public knowlege that everyone knows X) then, under discounting, agents can model their world as consisting of agents that act according to the public knowledge. For example, agents can use the social norm as the off-tree approximator and run Monte-Carlo tree search to account for potential breaking of the social norm. In this way, agents are able to come to the same equilibrium.



\subsection{Social network as abstraction}

In many situations, we're only interested in the social actions that each agent performs, so we can model a set of agents as interacting via social actions. In reality, these social actions are grounded in physical actions and if we're interested in the details of this, then each social action must come with an extension which is a set of sequences of physical actions that qualify as this social action. The agent must then choose a physical action in consideration of the social interpretations of that action. In general, the physical substrate of the agent's social world adds additional constraints to the sequence of social actions it may perform.

Modelling at the physical level also allows agents to perform actions that have multiple social meanings, so a single physical action or sequence of actions can perform mamy social actions. It is also possible for a physical action to be unclassifiable as a social action yet state changing in the social norm (e.g. I sit down at a restaurant, the waiter brings me the menu, i set fire to it). In this case the norm is considered null and new norms need to be negotiated.

\section{How do agents learn social norms?}


[Language, telling stories. By accidentally breaking social norms and being told off. It seems implausible that we learn social norms only through personal experience and direct observation: I haven't learned not to murder people by murdering a few and finding that it wasn't really worth it, nor even by whatching people murder others and imagining that it isn't worth it. Rather, I learn it on the social level, as part of the culture in which I live.]

A learner of social norms that only has access to observed physical behaviours must somehow learn the abstraction function, the social quality function and the transition function. If thrown into a world where a social norm is already prevalent and stable, and we assume people are guided by social norms, then all this can theoretically be done by minimising the error in predicting other's behaviours.

Alternatively, can can abstract over the physical and assume agents make observations at the social level of abstraction. This glosses over the learning of the abstraction function, which we learn from gossip etc. and focusses on the social dynamics. If agents are able to make social observations of their surroundings and their interactions then an agent can construct a probabilistic policy for each social norm (or if the norm type is itself negotiated, and we have a universal state and action space, then this can be a single policy...although it's hard to see the advantage of this compared to stratification by norm).


\section{how do agents negotiate roles to form new social connections?}
Context. Verbally.

Again, we can abstract over the physical details of this and assume there is a public vocabulary of norms, and connections have an associated social norm type-id.

\section{How do social norms evolve?}

If agents choose to create social connections at a rate proportional to their expected reward then some social norms will be popular and others not. Ultimately, some may die out.

New norms can be created by more or less intelligent mutation of existing norms (perhaps even unintentional misunderstandings or chance events), or specialisation of general-purpose norms: [this assumes there's a heirarchy of abstraction among norms, which we haven't talked about yet...] for example, hunting large game and sharing the meat may emerge as a specialisation of you-help-me-and-i'll-help-you norm...?

\subsection{Social judgement in social norms}

In a purely Q-learning environment, punishment and praise after the fact is ineffective in one-shot games. However, if a social norm consists of a whole policy, and is agreed upon at the beginning of an interaction, then a credible threat of contingent punishment and/or praise can be instrumental in making the policy a Nash equilibrium.

Perhaps social judgement goes two ways: it rewards the actor for socially beneficial behaviour, but also signals to everyone which behaviours should be copied and which avoided. This makes sense if social judgement is outcome based and/or defined on an abstract level. That is, the ability to make social judements allows everyone to easily see whether a given behaviour is good or bad, but it is more difficult to generate instances of behaviours that are good.

\subsection{Justice}

It's clear that concepts such as justice are largely shared and preceed law (i.e. are more than a respect for the rule of law). It's also clear that humans don't define justice in terms of reward, but rather in terms of some kind of social value (Has justice been done if I give you two camels for your daughter?).

Moreover, a potential new social norm could conceivably conflict with other social norms (even though they have different state spaces), and so a new social behaviour cannot become established as a norm if it conflicts with already established norms. This implies that there is much more structure to social norms than we have allowed so far. What exactly is this structure, is it essential and how do we represent it?

Justice isn't a social norm as we've defined it so far in that it doesn't seem to have an action space. It is more a property of a story (sequence of interactions between a set of agents). Unless it is a formula for how to take an unjust story and ``serve justice'' to transoform it into a just story.

Or perhaps a person performs an unjust act on another, and justice is the social norm of punishment of the actor and/or redress to the injured. The player performing the punishment/redress can be abstract (e.g. government). These are the norms. The concept of justice help us think about these norms.

Or perhaps better to think of justice as a concept that is part of the conceptual apparatus we use to reason \textit{about} social norms, and perhaps to intellecutally explain our innate feelings.

\section{Generative abstraction}

To capture this, we propose \textit{generative abstraction} (which is something like the inverse of a formal semantics of natural language: while a semantics goes from a sentence to an extension, an abstraction goes from a set of observations to a representation. The abstraction is generative in the sense that the representation space grows exponentially with the size of the concept space). 

Suppose we have a complex dynamic system we wish to model. Let its state space be $T$. Suppose also that we have two abstract models with state spaces $A$ and $B$, that are different abstractions of $T$. We can create a new, compound model with state space $A \times B$ by simply allowing the state of the system to be a pair of states: its A-state and its B-state. A simple approximate dynamics for the compound model can be formed by just using the dynamics of the corresponding sub-models to update the $A$ and $B$ states independently. A good example of this is to model the dynamics of a 2-dimensional projectile in a field by splitting into perpendicular $x$ and $y$ dimensions. In this case, the dynamics is exactly ``factorizable'' (i.e. no error is introduced). 


If we interpret being in an abstract state as meaning that the target state is contained within the extension of the abstract state, and two abstract models are correct, then the simple dynamics of a compound model is also correct and the extension of the compound state is the intersection of the extensions of the constituent states. This is true for the componding of any number of models. Although some state combinations are impossible (the intersection of the extensions of the consitiuent states is empty), if we start in a possible state, we will never reach an impossible state if the constituent models are correct.

\section{Generative social norms}

If we allow an agent to simultaneously play multiple roles towards another agent, and it is public knowledge how the social Q functions of these roles combine, then the number of social Q functions that can be described increases exponentially with the size of the vocabulary of social norms. Note that social states do not have extensions, they describe a social judgement/requirement rather than a state of the world, so we need not worry about the abstractions of the states. However, since the action spaces of the norms aren't directly comparable, we need to decide how to combine action spaces. The easiest way is to make the action space the product of the constituent action spaces (perhaps with the addition of the null action in each dimension). This certainly covers all possible social actions, but can certain action combinations be contradictory? This is what we touched on earlier when we said that one social norm can be an instance of another. This can be modeled if we show that the state space and action space of one model is an abstraction of another, and that the social Q-functions are somehow non-contradictory under this abstraction relation [perhaps the Q-value of an abstract (state, action) pair is the mean of the Q-values of the members of the extension of the pair. i.e. this is the measure of the correctness of an abstraction, so we can measure all possible abstractions - also the dynamics needs to be an abstraction ]. Do such heirarchies help us make decisions by allowing us to decide on an abstract action first, or at least rule-out abstract actions?

\section{Social state as predicates}

The social state of a set of agents can be represented as a set of agent IDs and a set of predicates on those IDs. Using predicates additionaly allows us to express relations with indirect objects, (e.g. ``I give you this ring''). If Alice and Bob both agree that Pred(Alice,Bob) then it becomes true by agreement, also to believe that Pred(Alice,Bob) is to believe that both Alice and Bob agree that Pred(Alice,Bob). Agents also agree that the performance of certain social acts changes the truth value of certain predicates (or, the act itself is universally understood as changing truth values of social predicates). The social acceptability of an act then becomes the acceptability of the change. This allows a more flexible way of describing social acceptability, for example ownership: if owns(Alice,Cake) then eats(X,Cake) is unacceptable unless hasPermissionToEat(X,Cake) or, if we allow higher order predicates isPermitted(eats(X,Cake)). 


\end{document}